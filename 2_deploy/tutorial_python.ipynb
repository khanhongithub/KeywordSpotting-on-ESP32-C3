{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f2067a",
   "metadata": {},
   "source": [
    "# MircoKWS deployment using TVM's Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28712a7",
   "metadata": {},
   "source": [
    "While the `tvmc` utility explained in `tutorial_tvmc.md` is very easy to use, in some situations it is more straightforward to interface with TVM directly via a Python script. While the tutorial in `tutorial_tvmc.md` contains a step by step guide on how to get started with TVM by compiling on the command line, this Jupyter notebook will introduce the TVMC Python API. It can be used analogously to the `tvmc` command line utility. More information can be found https://tvm.apache.org/docs/tutorial/tvmc_python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ebf2d8",
   "metadata": {},
   "source": [
    "Only the flow for generating kernels for an embedded device are covered at the moment. The used executor and features are aligned with the examples in `tutotial_tvmc.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37db34",
   "metadata": {},
   "source": [
    "## Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799e340",
   "metadata": {},
   "source": [
    "This tutorial is heavily inspired by the official \"microTVM with TFLite Models\" How-To in the TVM documentation (https://tvm.apache.org/docs/how_to/work_with_microtvm/micro_tflite.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a25e3",
   "metadata": {},
   "source": [
    "## Setting up the dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3805ae51",
   "metadata": {},
   "source": [
    "Please follow the instructions at the top of `install_tvm.md` to\n",
    "- Install required software\n",
    "- Setup and activate a virtual python environment\n",
    "- Install TVM\n",
    "  - via `tlcpack` python package, or\n",
    "  - by building it manually from source (See https://tvm.apache.org/docs/install/from_source.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bd80a",
   "metadata": {},
   "source": [
    "Make sure to activate the virtual environment before launching the jupyter kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65265f",
   "metadata": {},
   "source": [
    "The following cell is only required for custom TVM builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# sys.path.append(\"/PATH/TO/TVM/python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6a82f",
   "metadata": {},
   "source": [
    "Import Python dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e67250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import pathlib\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import tflite\n",
    "import tvm\n",
    "from tvm import relay, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae5e6a",
   "metadata": {},
   "source": [
    "## MicroKWS Flow using TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32d4f0",
   "metadata": {},
   "source": [
    "### Load and prepare the Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bab1d",
   "metadata": {},
   "source": [
    "First, define the path to the TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_MODEL = \"data/micro_kws_student_quantized.tflite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688dd31d",
   "metadata": {},
   "source": [
    "Next, load the file into a binary buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_buf = open(TFLITE_MODEL, \"rb\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d9784",
   "metadata": {},
   "source": [
    "Initialize the TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = tflite.Model.GetRootAsModel(tflite_model_buf, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cba2b8",
   "metadata": {},
   "source": [
    "Provide information on the input tensors (Name, DataType and Shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fecdb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = \"serving_default_input:0\"\n",
    "input_shape = (1, 1960)\n",
    "input_dtype = \"int8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ca073",
   "metadata": {},
   "source": [
    "Convert TFlite Model to Relay IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_tflite(\n",
    "    tflite_model, shape_dict={input_tensor: input_shape}, dtype_dict={input_tensor: input_dtype}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fce21",
   "metadata": {},
   "source": [
    "### Defining the runtime, target and executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0fc5f",
   "metadata": {},
   "source": [
    "The use target device is a generic MicroTVM target. We are using the CRT runtime in combination with the AoT executor as it is more lightweight compared to the full C++ runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = tvm.target.target.micro(\"host\")\n",
    "RUNTIME = tvm.relay.backend.Runtime(\"crt\", {\"system-lib\": False})\n",
    "EXECUTOR = tvm.relay.backend.Executor(\n",
    "    \"aot\", {\"interface-api\": \"c\", \"unpacked-api\": True, \"link-params\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b30470",
   "metadata": {},
   "source": [
    "### Define pass configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9e81e",
   "metadata": {},
   "source": [
    "These options will be passed to the `relay.build()` function in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"tir.disable_vectorize\": True,\n",
    "    \"tir.usmp.enable\": True,\n",
    "    \"tir.usmp.algorithm\": \"hill_climb\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b18c3",
   "metadata": {},
   "source": [
    "For more a detailed explanation of these options, see the `--pass-config` flags in `tutorial_tvmc.md`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042a238",
   "metadata": {},
   "source": [
    "### Apply Transformations to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f4db7",
   "metadata": {},
   "source": [
    "TFLite models typically use the `NHWC` format to store the weight of a convolutional layer. However, in some situations (especially when performing autotuning) a schedule using a `HCHW` layout can be more efficient. The following code, therefore, applies passes to the relay modules, which transform the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ff94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_layout = \"NCHW\"\n",
    "desired_layouts = {\n",
    "    \"nn.conv2d\": [desired_layout, \"default\"],\n",
    "    \"nn.conv2d_transpose\": [desired_layout, \"default\"],\n",
    "    \"qnn.conv2d\": [desired_layout, \"default\"],\n",
    "}\n",
    "\n",
    "# Convert the layout of the graph where possible.\n",
    "seq = transform.Sequential(\n",
    "    [\n",
    "        relay.transform.RemoveUnusedFunctions(),\n",
    "        relay.transform.ConvertLayout(desired_layouts),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with transform.PassContext(opt_level=3):\n",
    "    mod = seq(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9686d",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c9fb0",
   "metadata": {},
   "source": [
    "While this step looks pretty simple, it actually invoces the whole compilation pipeline provided by TVM. Depending on the complexity of the model and the enabled features, it might take a couple of seconds to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9146e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3, config=cfg):\n",
    "    module = relay.build(mod, target=TARGET, runtime=RUNTIME, executor=EXECUTOR, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada3045",
   "metadata": {},
   "source": [
    "### Export codegen artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b5862",
   "metadata": {},
   "source": [
    "For MicroTVM targets we are interested in the Model Library Format (MLF) artifact as it contains the sources required to build our target software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_library_format_tar_path = Path(\"gen/mlf.tar\")\n",
    "tvm.micro.export_model_library_format(module, f\"{model_library_format_tar_path}.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5649c23",
   "metadata": {},
   "source": [
    "### Optional: Use provided autotuning logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0ba60",
   "metadata": {},
   "source": [
    "Supply the tuning records (see tvm/data/ directory) like this and rebuild the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92726c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_records_file = Path(\"data/micro_kws_student_tuning_log_nchw_best.txt\")\n",
    "\n",
    "with tvm.autotvm.apply_history_best(tuning_records_file):\n",
    "    module_tuned = relay.build(\n",
    "        mod, target=TARGET, runtime=RUNTIME, executor=EXECUTOR, params=params\n",
    "    )\n",
    "\n",
    "model_library_format_tar_path_tuned = Path(\"gen/mlf_tuned\")\n",
    "tvm.micro.export_model_library_format(module_tuned, f\"{model_library_format_tar_path_tuned}.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d461e",
   "metadata": {},
   "source": [
    "Extract the MLF archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33043f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_library_format_tar_path_tuned.mkdir(exist_ok=True)\n",
    "tar = tarfile.open(f\"{model_library_format_tar_path_tuned}.tar\").extractall(\n",
    "    model_library_format_tar_path_tuned\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26071b61",
   "metadata": {},
   "source": [
    "### Support for physical hardware?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410ad86",
   "metadata": {},
   "source": [
    "MicroTVM supports a set of hardware boards which allows to directly compile, flash and run target software using a build model. However, the ESP32C3 target is currently not supported. Thus, the approach for the lab exercises is currently independent of the TVM framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
